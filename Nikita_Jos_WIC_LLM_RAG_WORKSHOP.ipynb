{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikitajos7/LLM-RAG-Workshop/blob/main/Nikita_Jos_WIC_LLM_RAG_WORKSHOP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Started\n",
        "First thing first, please go to **'File' > 'Save a Copy in Drive'** to create a copy of this notebook in your drive. Otherwise, any changes you make in this parent notebook won't be saved!!\n"
      ],
      "metadata": {
        "id": "6SBO4D42M-qU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Basic on Using Google Colab Notebook\n",
        "Noteboook are consist of multiple 'cells' and to run each cell, you can click on the Play button on the left of each cell, or navigate to a cell (click into the cell) and then press 'Shift+Enter'"
      ],
      "metadata": {
        "id": "wMip74-TONxg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39xizDnANwHH"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip -q install chromadb\n",
        "!pip -q install sentence-transformers\n",
        "!pip -q install PyPDF2\n",
        "!pip -q install google.generativeai\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import PyPDF2\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from dotenv import load_dotenv\n",
        "nltk.download('punkt')\n",
        "load_dotenv()\n",
        "api_key = os.getenv('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "cQYgU7I9OQFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read pdf content\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in range(len(reader.pages)):\n",
        "            text += reader.pages[page].extract_text()\n",
        "        return text\n",
        "\n",
        "pdf_text = extract_text_from_pdf(\"syllabus.pdf\") #replace with the name of pdf file you imported"
      ],
      "metadata": {
        "id": "XdNc-VsxPrZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the pdf_text by sentences\n",
        "sentences = sent_tokenize(pdf_text)\n",
        "print(len(sentences)) # should be greater than 1"
      ],
      "metadata": {
        "id": "QwOxS1SiScgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a ChromaDB client instance and a db collection\n",
        "client = chromadb.Client()\n",
        "collection = client.create_collection(\"my_collection\")"
      ],
      "metadata": {
        "id": "RRDpssXMN4Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fixed_size_chunking(text, chunk_size=5, overlap_size=2):\n",
        "    # Group sentences into chunks with overlap\n",
        "    stride = chunk_size - overlap_size # overlap by 2 sentences\n",
        "    chunks = [' '.join(sentences[i:i + chunk_size]) for i in range(0, len(sentences), stride)]\n",
        "\n",
        "    return chunks\n",
        "\n",
        "chunks = fixed_size_chunking(sentences)"
      ],
      "metadata": {
        "id": "pEEUWnuXEnUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks) # should be greater than 1"
      ],
      "metadata": {
        "id": "urcNylyRTRIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download embedding model and use it to embed knowledge base\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # You can choose another model https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
        "documents = chunks\n",
        "embeddings = model.encode(documents)\n",
        "\n",
        "# Store embeddings in Chroma DB\n",
        "for idx, embedding in enumerate(embeddings):\n",
        "    print(f\"===Adding Document {str(idx)} to Collection: \")\n",
        "    print(documents[idx])\n",
        "    collection.add(\n",
        "        ids=[str(idx)],\n",
        "        documents=[documents[idx]],\n",
        "        embeddings=[embedding.tolist()]\n",
        "    )"
      ],
      "metadata": {
        "id": "zhNSYhuZS6dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to different queries!\n",
        "query = \"When is the midterm?\""
      ],
      "metadata": {
        "id": "VkHDWZvVan7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=2 # retrieve top 2 most relevant document\n",
        ")\n",
        "context = results['documents'][0]\n",
        "print(context)"
      ],
      "metadata": {
        "id": "4r33uosiaJTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also feel free to adjust the prompt as well (prompt tuning!!)\n",
        "prompt = f\"\"\"\n",
        "Answer the question based only on the following context: {context}\n",
        "Answer the question based on the above context: {query}\n",
        "\"\"\"\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "P7S8H7PMZOT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Gemini API key at https://aistudio.google.com/app\n",
        "# DO NOT USE UCSD GMAIL ACCOUNT! (you won't be able to access the AI Studio)\n",
        "genai.configure(api_key=api_key) # paste in your api key here\n",
        "\n",
        "# Create a Gemini model instance\n",
        "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "\n",
        "# Generate text\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the generated text\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "26dGYyOuV2LI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}